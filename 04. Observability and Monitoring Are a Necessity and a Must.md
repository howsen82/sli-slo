# Observability and Monitoring Are a Necessity and a Must

In previous chapters, we discussed the hierarchy of reliability engineering and the importance of incorporating observability as its own practice. Developing robust **Service Level Indicators** (**SLIs**) requires deep comprehension of your application, system, or platform, enabling precise measurement of its components. This necessitates establishing suitable mechanisms in advance to ensure the requisite level of observability and monitoring of key aspects.

This chapter provides an overview of both observability and monitoring, to highlight their integral connection with SLIs and **Service Level Objectives** (**SLOs**). Its aim is to cultivate this mindset throughout your journey with SLIs and SLOs and embed a solid understanding of not only the importance of both but also the differences between them. The goal of this chapter is not to suggest a specific product or solution or even a way of working. It is, rather, to highlight processes and solutions to support improved monitoring and observability to drive SLIs.

We’ll be covering the following main topics:

* Observability and monitoring at its core
* The pillars of observability
* Integrating observability thinking into the SLI and SLO journey
* Strategic monitoring for effective measurement

Now, let’s get started!

# Observability and monitoring at its core

Observability and monitoring serve as the foundational pillars of modern **site reliability engineering** (**SRE**) practices. In essence, observability refers to the ability to infer the internal state of a system based on its external outputs. This involves collecting and analyzing data from various sources within the system to gain insights into its behavior, performance, and health. Monitoring, on the other hand, involves the continuous observation of key metrics and indicators to detect and respond to anomalies or issues in real time. Together, observability and monitoring provide SRE teams with the visibility and insights needed to ensure the reliability and performance of their systems.

It is often the case that the two concepts are mistaken for one another, used interchangeably, or not clearly defined in the context of their usage. While the goal is not to focus on observability and monitoring as a practice, I hope to provide additional insight as to why it is important to include observability as a pillar of reliability engineering, differentiate it from monitoring, and showcase its relationship and dependency to creating quality SLIs that meet their SLOs. Let’s go!

## The significance of observability and monitoring in reliability engineering

Observability and monitoring play a crucial role in reliability engineering by enabling teams to gain a deep understanding of system behavior and performance. Before we begin the discussion, it is important to understand that behavior can be described as an event that occurs and leads to the triggering of another event internally or within another system. On the other hand, performance can be described as a measurement of the amount of useful work or output of a system, for instance, its speed, throughput, or response times to some requests.

Through comprehensive observability practices, SRE teams can collect and analyze these sorts of data types from across the entire system stack, including infrastructure, applications, and user interactions. This allows for the ability to identify patterns, diagnose issues, and optimize performance to meet SLOs. Additionally, effective monitoring ensures that SRE teams can quickly detect and respond to incidents, minimizing downtime and ensuring a seamless user experience.

The two concepts work together to enhance the amount of data availability for increased accuracy when measuring and quantifying internal events. According to AWS, *“Monitoring is the process of collecting data and generating the reports on different metrics that define the system’s health”* (AWS, 2024). Observability is the aggregation of the data being monitored in a more investigative manner. Observability takes the lead when looking at distributed system components’ interactions and utilizing data collected through the process of monitoring to find the root cause of an issue. If we are not observing the right things in the right places, then how do we accurately move up the hierarchy of reliability engineering?

It is easy to misconstrue or use interchangeably the observability and monitoring concepts. Therefore, it is important to highlight the differences between the two. As previously mentioned, monitoring answers the following questions:

* **What happened?** Resource utilization (CPU, network, etc.) spike?
* **Is this a known issue?** Does incident management data support a recurring issue?
* **How did we previously resolve it?** Do we have an internal knowledge base or some documentation regarding the temporary fix?

Monitoring informs both internal engineers and business stakeholders about the system’s health. While end users might not directly monitor internal metrics such as CPU usage, the impact of such metrics on user experience, such as response times or error rates, should align with defined SLIs and SLOs that reflect user expectations. A customer securing a plane ticket through an airline’s web or mobile application is not going to relate to “CPU usage is nearing maximum capacity.” This representation of monitoring is more important to the engineers looking to mitigate and potentially root cause an issue within **Service Level Agreement** (**SLA**) guidelines.

On the other hand, observability takes a more investigative approach to better understand how to prevent an issue from happening again:

* **Why did it happen?** Did we experience exhaustive resource consumption due to increased use due to performance testing or data center outages?
* **Is the system performant?** Is the system able to perform according to “defined customer expectations” under the current conditions?
* **How do we improve resiliency?** Was the previous fix a temporary patch, incorrect pushed code, inaccurate understanding of user requirements, etc.?

Although the two are different conceptually, they work together to achieve a level of observability that supports high standards for metric definition and creating SLIs, especially in distributed environments. See *Figure 4.1* for further reference.

![Figure 4.1 – Observability versus monitoring question-based concepts](https://static.packt-cdn.com/products/9781835889381/graphics/image/B22155_04_1.jpg)<br>
**Figure 4.1 – Observability versus monitoring question-based concepts**

Observability and monitoring are integral to the definition and management of SLIs and SLOs. SLIs are metrics that measure the performance and reliability of a system, such as latency, error rates, and throughput. These indicators provide the data needed to assess whether the system is meeting SLOs. SLOs define the targets for acceptable performance, based on those SLIs, and help to align system behavior with business objectives and user expectations. By leveraging observability tools, SRE teams can continuously track SLIs and ensure SLOs are met within the defined SLA. This will further allow organizations to set realistic targets for system reliability and performance, while also providing a framework for continuous improvement.

Proactive SLO management is essential for effective SLI and SLA alignment in SRE. SRE teams must define clear SLOs that reflect user expectations and monitor SLIs to ensure these objectives are consistently met. This involves continuous measurement, regular reviews, and adjustments to keep the system aligned with business goals while meeting SLA requirements. This involves setting up alerts and triggers based on predefined thresholds, conducting regular performance reviews, and performing proactive capacity planning to ensure that systems can handle expected loads. By adopting a proactive approach to observability and monitoring, organizations can minimize the impact of incidents, improve system reliability, and enhance the overall user experience.

## Data-driven decision-making for SLI and SLO optimization

Observability and monitoring empower SRE teams to make data-driven decisions when optimizing SLIs and SLOs. By collecting and analyzing large volumes of data from diverse sources, teams can gain valuable insights into system performance trends, identify areas for improvement, and prioritize efforts accordingly. This data-driven approach enables teams to continuously monitor and adjust SLIs to ensure they align with SLOs, based on real system performance data and evolving user expectations. Regular reviews of SLOs, discussed in [*Chapter 12*](https://subscription.packtpub.com/book/cloud-and-networking/9781835889381/12), should ensure they are realistic and meet business objectives, with defined error budgets to assess performance against SLAs. Ultimately, data-driven decision-making ensures that SRE teams can continuously improve system reliability and performance to deliver exceptional user experiences.

Observability and monitoring together enable continuous improvement through feedback loops in SRE practices. By collecting data on system performance and user interactions, teams can identify opportunities for optimization and innovation. This feedback loop allows teams to adjust SLIs based on real-time data and monitor how those changes impact SLOs. This continuous iteration helps to refine service levels and improve overall system performance while ensuring SLAs are consistently met within the defined error budget. Additionally, feedback loops facilitate collaboration and knowledge sharing across teams, enabling organizations to leverage collective insights and expertise to drive continuous improvement initiatives. By embracing feedback loops, organizations can foster a culture of learning and innovation that accelerates their journey toward greater reliability and performance.

## Challenges and opportunities in observability and monitoring

While observability and monitoring offer significant benefits to SRE practices, they also present unique challenges and opportunities. An organization can experience various challenges due to the complexity of modern distributed systems, such as the following:

* The inability to collect, analyze, and interpret data effectively.
* Increased data overload.
* Increased needs for navigating issues related to data privacy, security, and compliance when implementing observability solutions.

However, it is important to highlight that these challenges also present the following opportunities for innovation and growth:

* Improved reliability of organizational data.
* Increased accessibility of accurate data.
* Internal organizational alignment resulting from a broader visibility of internal infrastructure.

By investing in advanced observability tools and techniques, organizations can overcome these challenges and unlock new possibilities for optimizing system reliability and performance. Ultimately, by embracing the power of observability and monitoring, organizations can achieve greater agility, resilience, and competitiveness in today’s digital landscape.

# The pillars of observability

Observability is central to maintaining and improving the performance, reliability, and overall health of any system. At its core, observability relies on four fundamental components: **logs**, **metrics**, **traces**, and **events**. Each component plays a crucial role in providing insights into the inner workings of a system, helping engineers and operators understand its behavior and diagnose issues effectively. Remember, when we can observe the correct components at the right log level, we are able to productively monitor and create quality SLIs and SLOs.

*Figure 4.2* depicts the four pillars of observability, including “events” on which the other three pillars rely heavily. We can also think of the pillars of observability as passive sequential tasks that include other observability tasks. As it relates to observability, we can think of each pillar within the following context as independent concepts that also occur in a sequential order.

![Figure 4.2 – Pillars of observability](https://static.packt-cdn.com/products/9781835889381/graphics/image/B22155_04_2.jpg)<br>
**Figure 4.2 – Pillars of observability**

Let’s take a moment to review what each pillar means according to industry standards, and its role within observability.

![Figure 4.3 – Observability pillar definitions](https://static.packt-cdn.com/products/9781835889381/graphics/image/B22155_04_3.jpg)<br>
**Figure 4.3 – Observability pillar definitions**

As depicted in *Figure 4.3*, for the logging process to be invoked, we must first experience some event within our application, platform, or system that occurs. An event can include errors or warnings regarding changes in your system. These changes can include a pod within your cluster crashing due to disk storage being at full capacity or your organization’s website being down due to network throttling or a server outage in the associated data center. Logs provide a narrative of what transpired within your distributed environment, helping to identify the root causes of issues and track down anomalies. By analyzing logs, engineers can gain context around specific incidents and trace the sequence of events leading up to them.

The events that occur within your system provide an overall measurement via its associated metric regarding the health or performance of your system. Traces, although tied to events, are specific to requests within an end-to-end workflow where each touchpoint within a trace is assigned a span ID, while the collective spans make up the trace, which is assigned a trace ID. We can think of each in the following contexts:

* **Metrics**: Metrics are quantitative measurements that provide a snapshot of the current state of a system. They can collectively make up **key performance indicators** (**KPIs**) and are typically aggregated over time intervals. Metrics serve as the foundation for defining SLIs, which are used to measure how well a system is meeting its SLOs. These metrics can be aggregated over time intervals to determine whether the SLOs are being met and whether the system is performing with acceptable thresholds. Common metrics include CPU utilization, memory usage, request latency, and error rates.

* **Events**: Events are discrete occurrences or notifications that signify significant changes or milestones within a system. They can range from user actions and system state transitions to infrastructure events and external integrations. Events trigger real-time monitoring and alerting, allowing SRE teams to respond promptly to potential SLA breaches or issues that may consume the error budget. These events can represent failures, warnings, or other significant state changes that impact the service’s ability to meet its SLOs. Event-driven architectures leverage events to decouple components and enable asynchronous communication.

* **Logs**: Logs are textual records generated by a system that capture events, actions, and state changes over time. They provide a detailed chronological account of what has happened within a system, including errors, warnings, and informational messages. Logs are invaluable for troubleshooting issues, auditing system activity, and analyzing historical data.

* **Traces**: Traces offer end-to-end visibility into the flow of requests, providing detailed insights into latency and performance bottlenecks. By correlating traces with defined SLIs, SRE teams can assess whether the system meets its SLOs for response times, error rates, and throughput across services, identifying areas that could impact the SLA. Traces consist of individual spans, each representing a unit of work within a request. By correlating spans across services, traces enable engineers to diagnose performance bottlenecks, identify dependencies, and understand the overall request flow. Tracing is particularly valuable in microservices architectures and complex distributed systems.

Each observability pillar contributes a unique type and level of visibility of the overall performance and events within the organization. This collectively forms a comprehensive picture of its behavior and performance to further understand SLIs and SLOs. By leveraging each of the four observability pillars in tandem, organizations can achieve a holistic understanding of their systems, empowering teams to make informed decisions and troubleshoot effectively, while continuously improving system reliability and performance.

# Integrating observability thinking into the SLI and SLO journey

Now that we have covered a few concepts within observability, let’s focus on the practice as it relates to reliability engineering and the journey toward defining and achieving organization SLIs and SLOs. Observability is not merely about setting metrics. It’s a strategic approach to ensuring systems perform as expected and meet user needs, by capturing the right data and information in the right places and in alignment with customer expectations.

Observability is the ability to infer the internal state of a system based on its external outputs, so it’s important that we understand how this process maps to customer expectations without confusing it with the practice of monitoring.

Integrating observability thinking into the SLI and SLO journey involves a fundamental shift in mindset. It’s about recognizing that understanding system behavior requires more than just monitoring predefined metrics. Instead, it necessitates a holistic approach that encompasses not only what can be measured but also how it’s measured and interpreted. Observability encourages a proactive stance toward reliability. It prompts teams to proactively define and measure SLIs that accurately reflect user experience and system reliability, enabling them to anticipate potential SLO violations before they occur, rather than just reacting to incidents after the fact. By embedding observability into the fabric of SLI and SLO definitions, organizations can foster a culture of resilience and continuous improvement.

## Building observability into the process

Defining meaningful SLIs and SLOs is the cornerstone of any reliability engineering initiative. However, traditional approaches often fall short of capturing the full spectrum of system behavior and user experience. This is where observability steps in, offering a more opinionated and dynamic lens through which to assess system performance. Building observability into the process of defining SLIs and SLOs entails a shift from static, predefined metrics to a more adaptive and responsive framework. It involves asking not only what we want to measure but also how we can best observe and interpret the signals emitted by our systems.

# Strategic monitoring for effective measurement

With the fast-paced development of modern technology, strategic monitoring is indispensable for ensuring the seamless operation of complex systems. At its core, strategic monitoring is centered around the measurement of SLIs that are used to define and assess SLOs. These SLOs reflect the commitments made to users regarding system reliability, performance, and availability. To achieve strategic monitoring excellence, it’s imperative to establish clear, actionable SLOs that align with business objectives.

Effective strategic monitoring begins with a deep understanding of the user experience and the critical aspects of the system that impact it. By identifying key user journeys and critical system components, organizations can define meaningful SLOs that reflect user expectations. For instance, an e-commerce platform may set SLOs for page load times, checkout success rates, and uptime during peak shopping hours.

Strategic monitoring involves continuously assessing SLIs to ensure they are accurate and reflective of user needs. SLOs should be reviewed and refined periodically, in collaboration with stakeholders, to ensure they remain aligned with evolving user demands, technological advancements, and business objectives. Regular review sessions with stakeholders ensure that SLOs remain relevant and achievable. Additionally, leveraging historical data and user feedback enables organizations to refine SLO targets for optimal performance.

In essence, strategic monitoring is not just about collecting data—it’s about leveraging that data to drive actionable insights and improvements. By prioritizing SLO measurement and aligning it with business objectives, organizations can enhance user satisfaction, mitigate risks, and stay ahead in today’s competitive landscape.

## Implementing strategic monitoring systems

Implementing strategic monitoring systems requires a combination of robust processes, cutting-edge technologies, and organizational alignment. Kickstarting this initiative in the right way can only enhance the SLO journey and experience for your organization. It is also important to reiterate the importance of establishing a cross-functional team comprising individuals contributing various skillsets from engineering, operations, and business organizational domains, as mentioned in [*Chapter 3*](https://subscription.packtpub.com/book/cloud-and-networking/9781835889381/3). This team will drive the strategic monitoring initiative from inception to execution. The process can be described in the following simple tasks, similarly outlined in the publication *7 Steps for Setting Up a Monitoring and Evaluation* *System (2022)*:

1. Define clear objectives and scope:

   * Identify systems and services to be monitored.
   * Define the purpose and scope of the system you are monitoring.
   * Agree on outcomes and objectives—theory of change (including indicators).

2. Organize your data:

   * Plan data collection and analysis (including development of tools).
   * Plan the organization of the data.
   * Plan the information flow and reporting requirements (how and for whom?).

3. Identify suitable monitoring tools and platforms:

   * Includes the capability for managing reliability engineering data, for example, SRE incident management platforms or SLO platforms.
   * Ensure scalability, flexibility, and integration capabilities are included.

4. Monitor workflows and processes:

   * Develop an internal reflection process. This aligns with the retrospectives mentioned in previous chapters.
   * Plan the necessary resources and skills. Hire or train staff to support ongoing maintenance.

5. Transition into an iteration phase:

   * Implement dashboards and other mechanisms to visualize the state of monitored systems.
   * Implement processes to review and make changes to SLIs or SLOs as needed.

   ![Figure 4.4 – Process for building scalable monitoring systems](https://static.packt-cdn.com/products/9781835889381/graphics/image/B22155_04_4.jpg)<br>
   **Figure 4.4 – Process for building scalable monitoring systems**

Before beginning any initial tasks regarding implementing strategic monitoring systems for enhanced observability, it is key to first define clear objectives and scope. This involves identifying the systems and services to be monitored, along with the corresponding SLOs. SLOs for your monitoring system can and will likely fall under the **Monitoring** column depicted in *Figure 4.1*. Collaboration between development and operations teams is crucial at this stage to ensure that SLOs are realistic and achievable, as both groups will understand best what the expectations are regarding system performance and availability.

Once objectives have been defined and data has been organized, organizations can proceed to select suitable monitoring tools and platforms. It is essential that monitoring tools can collect and report on SLIs that directly measure the performance relative to the defined SLOs. These tools should provide the necessary visibility into how well the system is meeting its reliability targets and allow teams to track progress toward SLO compliance. Additionally, the selected tools should offer scalability, flexibility, and integration capabilities to accommodate future or potential growth and changes in the technology environment.

With the appropriate tools in place, organizations can then establish monitoring workflows and processes. This includes defining escalation policies, setting up automated alerts, and creating dashboards for real-time visualization of observability data. Regular training sessions and knowledge-sharing initiatives ensure team members can effectively use the monitoring systems.

Continuous iteration and improvement are key principles in the implementation of strategic monitoring systems. Regular reviews and retrospectives help identify areas for optimization and refinement. By embracing a culture of learning and adaptation, organizations can maximize the value derived from their strategic monitoring efforts.

## Observability platforms and tooling for SLI and SLO monitoring

Observability platforms and tools play a pivotal role in enabling organizations to measure and manage their SLOs effectively. These platforms provide the necessary infrastructure for collecting, processing, and analyzing SLIs in real time. Let’s explore some of the key features and capabilities of observability platforms and tools for SLI and SLO monitoring.

Observability platforms offer comprehensive data collection capabilities, allowing organizations to monitor a wide range of metrics across their systems and services. These metrics may include the following:

* Response times
* Error rates
* Throughput
* Resource utilization

By aggregating and correlating these metrics, organizations gain valuable insights into the health and performance of their systems.

Moreover, observability platforms provide advanced analytics and visualization features that enable teams to derive actionable insights from the collected data. Interactive dashboards, customizable charts, and trend analysis tools empower users to identify patterns, anomalies, and performance bottlenecks quickly. This real-time visibility into system behavior is essential for proactively addressing issues and optimizing performance.

Observability platforms often integrate with other tools and systems within the organization’s ecosystem, such as incident management platforms and CI/CD pipelines. This seamless integration streamlines workflows and enables automated responses to detected issues, thereby reducing the mean time to resolution and minimizing downtime.

In addition to these features, observability platforms prioritize scalability, reliability, and security to meet the needs of modern enterprises. Cloud-native architectures, distributed data processing, and robust access controls are some of the hallmarks of leading observability platforms.

By harnessing the power of these platforms, organizations can ensure the reliability, performance, and availability of their systems, thereby enhancing the user experience and driving business success.

## Techniques for real-time alerting, visualization, and reporting

As a reminder, the goal of this chapter is not to suggest a specific product, solution, or way of managing your internal infrastructure and logistics. It is, rather, to raise awareness of the processes and solutions available to support improved monitoring and observability and build more accurate SLIs. Real-time alerting, visualization, and reporting are essential components of any observability strategy, enabling organizations to detect and respond to issues swiftly while providing stakeholders with actionable insights.

Clear alerting thresholds, defined based on the SLO targets derived from SLIs, are essential for ensuring that the system meets its reliability objectives. Automated alerting mechanisms, such as PagerDuty integrations or email notifications, should be configured to notify stakeholders when SLIs exceed predefined thresholds that indicate a failure to meet the SLOs.

Furthermore, visualization plays a crucial role in enabling teams to make sense of complex observability data. Interactive dashboards and customizable charts allow users to visualize key SLIs and track SLO performance in real time, enabling teams to proactively address potential breaches before they affect service reliability. In addition, scheduled reports, executive summaries, and ad hoc queries empower stakeholders to stay informed about the health and performance of the systems.

Additionally, integrating reporting tools with collaboration platforms will help to facilitate seamless communication and collaboration among teams. The right tool is always the tool that the governing organization needs or is best suited to get the job done. You’ll see SRE-related tools highlighted throughout many chapters of this book; these are not recommendations but are mentioned to give you somewhere to start if you decide to look into it today.

Let’s further discuss important characteristics of observability and monitoring platforms:

* **Metrics collection**: Processes should focus on gathering metrics from various sources within the system, including application logs, infrastructure metrics (CPU usage, memory usage, and network traffic), and user interactions. Specialized tools such as Prometheus, StatsD, or custom instrumentation can aid with collecting these metrics efficiently.

* **Alerting rules**: Define alerting rules based on predefined thresholds or anomaly detection algorithms. These rules trigger alerts when certain conditions are met, such as a sudden increase in error rates, high latency, or resource saturation.

* **Real-time monitoring**: Implement real-time monitoring systems that continuously ingest and process metrics data to provide insights into the health and performance of the system. Tools such as Grafana, Kibana, or custom dashboards can visualize this data in real time, enabling operators to detect issues promptly.

* **Anomaly detection**: Employ machine learning algorithms or statistical techniques to detect anomalies in the system behavior. These anomalies could indicate potential issues or unusual user activity that requires investigation.

* **Automated remediation**: Integrate alerting systems with automated remediation workflows to respond to alerts quickly—for example, automatically scaling up resources in response to increased demand or restarting failed services.

* **Distributed tracing**: Implement distributed tracing to understand the flow of requests across various components of the system. Specialized solution offerings such as Jaeger or Zipkin can enable the visualization of request traces and identify performance bottlenecks or errors.

* **SLOs and SLIs**: Define SLOs and SLIs to measure the reliability and performance of the system from a user’s perspective. Monitor these SLIs in real time and trigger alerts when they deviate from the defined objectives.

* **Historical analysis**: Store historical metrics data for trend analysis and capacity planning. By analyzing historical SLI data, you can identify trends, forecast potential SLO violations, and optimize resources to ensure continued alignment with SLOs.

* **Integration with incident management**: Integrate alerting systems with incident management platforms such as PagerDuty or Opsgenie to streamline the incident response process. Automatically create and escalate incidents based on incoming alerts, ensuring the timely resolution of issues. This can help to improve your organization’s ability to integrate incident management data into the metric collection step previously mentioned.

* **Continuous improvement**: Continuously review and refine your observability practices based on feedback and lessons learned from past incidents. Regularly update alerting rules, visualization dashboards, and monitoring configurations to adapt to changes in the system architecture and user requirements.

In addition to these techniques, organizations can and should prioritize usability, scalability, and reliability when selecting alerting, visualization, and reporting tools. Often, incident management is missing as a part of the metric collection process, as opposed to merely managing and responding to alerts. We will highlight this in [*Chapter 14*](https://subscription.packtpub.com/book/cloud-and-networking/9781835889381/14), later in the book. User-friendly interfaces, scalability to handle large volumes of data, and robustness to withstand failures are critical considerations in ensuring the effectiveness of these capabilities.

# Summary

Although real-time alerting, visualization, and reporting are indispensable components of observability strategies, it’s important to understand that each enables observability, and understanding how to utilize events, metrics, traces, and logs is the goal. The fundamental components work together to enable organizations to detect, analyze, and respond to issues swiftly while providing stakeholders with actionable insights, thus better aligning the product to achieve success with the customer.

By leveraging these techniques effectively, organizations can enhance the reliability, performance, and availability of their systems, thereby driving business success. If observability acts as the foundational layer of SRE, setting the reliability engineering practice up for success through increased observations and transparency, then it is necessary to make mention of its capabilities here. It is even more important to ensure you incorporate it into your reliability journey to build a solid foundation for long-term SLO management.

In the next chapter, we will focus on some of the economic benefits of integrating reliability with SLIs and SLOs into your organization. We’ll also cover a few examples of issues that can arise if you decide not to, before we move on to the workshop chapters.

# Further reading

You can review the articles and books referenced here for additional information about the concepts mentioned in this chapter:

* *AWS. (2024). The Differences Between Monitoring and Observability*. Retrieved from: <https://aws.amazon.com/compare/the-difference-between-monitoring-and-observability/>.
* *EvalCommunity: Jobs & Experts. (2023, Sept 10). Smart Indicators in Monitoring and Evaluation*. Retrieved from: <https://www.evalcommunity.com/career-center/smart-indicators/>.
* *Neymeyer, S. (2022, Jan 6). 7 Steps for Setting Up a Monitoring and Evaluation System*. Retrieved from: <https://www.activityinfo.org/blog/posts/2022-01-06-seven-steps-for-setting-up-a-monitoring-and-evaluation-system.html#:~:text=Step%201%3A%20Define%20the%20purpose,the%20organization%20of%20the%20data>.
* *Practical Mel. (2023, December 19). How to Set M&E Objectives*. Retrieved from: <https://practicalmel.com/how-to-set-me-objectives/>.
